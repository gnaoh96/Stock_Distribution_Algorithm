{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b616097-97ae-42d0-9315-04564a14e3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libs and set options\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('mode.chained_assignment', 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e9daf9-d59d-4681-be1c-f7123c1b062b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define location path\n",
    "path = \"/Users/hoangpham/Downloads/GoodsDistribution/\"\n",
    "path_ho = \"/Users/hoangpham/Downloads/GoodsDistribution/HO_Stock.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b3cbb5-c043-483e-bf45-b83cf8a87203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['ĐàNẵng', 'HàNội', 'HồChíMinh', 'MiềnĐông', 'MiềnTây']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define dataframe & transform Area, avoid mistakes\n",
    "df = pd.read_excel(f'{path}Stocks.xlsx')\n",
    "list_area = df['Area'].values.tolist()\n",
    "\n",
    "new_area = [re.sub(r'\\d+', \"\", re.sub(r'\\s+', \"\", area)) for area in list_area]\n",
    "df = df.drop(['Area'], axis =1)\n",
    "df['Area'] = new_area\n",
    "\n",
    "list_area_2 = df['Area'].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'ĐàNẵng'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.iterrows())[0][1]['Area']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391c5f5a-3b82-4c8f-b6b0-51a87f8ef148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_1 = pd.read_excel(path_ho)\n",
    "\n",
    "df_2 = [df[df.Area == list_area_2[area]] for area in range(0,len(list_area_2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4356834-fdcf-45c4-80e8-e2986e6c588a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define min & max DOS (optimize 30 days)\n",
    "min_day = 26\n",
    "max_day = 34\n",
    "\n",
    "# define drop columns, sort orders, classification good's statement function\n",
    "def drop_sub_columns_pool1(df):\n",
    "    df = df.drop(['StockQuantity', 'SO1', 'SO2', 'SO3', 'SO4', 'AvgSO', 'SellPower', 'DOS', 'Statement'],axis=1)\n",
    "    return df\n",
    "\n",
    "def drop_sub_columns_pool2(df):\n",
    "    df = df.drop(['SellPower', 'DOS', 'Statement', 'Balance_num'],axis=1)\n",
    "    return df\n",
    "\n",
    "def sort_by_balance(df):    \n",
    "    df = df.sort_values(by='Balance_num' ,ascending=False)\n",
    "    return df\n",
    "\n",
    "def DOS_Classify (condition):\n",
    "    if condition < min_day:\n",
    "        return \"Thiếu hàng\"\n",
    "    if condition > max_day:\n",
    "        return \"Thừa hàng\"\n",
    "    if min_day <= condition <= max_day:\n",
    "        return \"Đủ hàng\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414b474d-fad8-4e85-9296-7503567b0755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define distribution function\n",
    "def allotment(df_1,df_2):\n",
    "\n",
    "    # if hasattr(df_stock_HO_raw,\n",
    "    #             'attr_name') and hasattr(df_2,\n",
    "    #             'attr_name'):\n",
    "\n",
    "    list_pool_1 = list()\n",
    "    list_pool_2 = list()\n",
    "    list_sheet_name_pool_1 =list()\n",
    "    list_sheet_name_pool_2 =list()\n",
    "    pool1_tong_hop = pd.DataFrame()\n",
    "    pool2_tong_hop = pd.DataFrame()\n",
    "    \n",
    "    #transform data from df_2 list\n",
    "    for df in df_2:\n",
    "\n",
    "        data = df.loc[:,['Area','storeId','storeName', 'productId','productName'\n",
    "                    ,'SO1','SO2','SO3','SO4', 'AvgSO','StockQuantity']].copy()\n",
    "        \n",
    "        #fillna with 0\n",
    "        data = data.fillna(np.nan).replace([np.nan], 0)\n",
    "        \n",
    "        #limit SalePower < 0\n",
    "        data['AvgSO'] = data['AvgSO'].clip(lower=0)\n",
    "\n",
    "        #Sell power\n",
    "        data['SellPower'] = round(data['AvgSO'].div(7),3)\n",
    "        #DOS: return the quantity fit with sell power\n",
    "        data['DOS'] = round(data['StockQuantity'] / data['SellPower'],0)\n",
    "\n",
    "        #DROP residual column df.drop([index])\n",
    "        #Sort values by DOS\n",
    "        data = data.sort_values(by=['DOS'], ascending = False)\n",
    "        #Classify statement\n",
    "        data['Statement'] = data['DOS'].apply(lambda x: DOS_Classify(x))\n",
    "        data['Balance_num'] = ''\n",
    "        \n",
    "        ### 1st loop\n",
    "        for i, row in data.iterrows():\n",
    "            val = row['Statement']\n",
    "            \n",
    "            if val == \"Thừa hàng\":\n",
    "                data.at[i,'Balance_num']= math.ceil( data['StockQuantity'][i] - data['SellPower'][i] *max_day)   \n",
    "                \n",
    "            if val == \"Thiếu hàng\":\n",
    "                data.at[i,'Balance_num'] = round(-data['StockQuantity'][i] +data['SellPower'][i] *min_day,0)\n",
    "                \n",
    "            if val == \"Đủ hàng\":\n",
    "                data.at[i,'Balance_num'] = 0\n",
    "\n",
    "        # Initialize pool_1 - Dư hàng\n",
    "        pool_1 = data.loc[data['Statement'] == 'Thừa hàng']\n",
    "        pool_1 = sort_by_balance(pool_1)\n",
    "        \n",
    "\n",
    "        ## Initialize pool_2 - Thiếu hàng\n",
    "        pool_2 = data.loc[data['Statement'] == 'Thiếu hàng'] \n",
    "        pool_2 = sort_by_balance(pool_2)\n",
    "\n",
    "        # Stores in HCM & HN\n",
    "        if list(data.iterrows())[0][1]['Area'] == 'HồChíMinh' or list(data.iterrows())[0][1]['Area'] == 'HàNội':\n",
    "        \n",
    "            #Setup new pool_1_transfer_clone ; pool_2_get_clone\n",
    "            pool_1_transfer_clone = pool_1\n",
    "            pool_2_get_clone = pool_2\n",
    "        \n",
    "            # Identify\n",
    "            # First Initialize cache_transaction\n",
    "            cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "            \n",
    "            # print(cache_transaction)\n",
    "            # Transaction dataframe\n",
    "            ## Rule: Compare the productId and Balance number\n",
    "            \n",
    "            #define dataframe storage logs transaction and goods to HO (excess stock)\n",
    "            transaction = pd.DataFrame(columns = ['storeId_transfer','storeName_transfer', 'storeId_receive','storeName_receive','productId','productName','Quantity'])\n",
    "            \n",
    "            pool_3_move_to_HO = pd.DataFrame(columns = ['storeId_HO','storeName_HO', 'productId','productName','Quantity'])\n",
    "            \n",
    "            while True:\n",
    "                # The amount of goods exceeded pool_1\n",
    "                n   =   pool_1_transfer_clone.iloc[0]['Balance_num']\n",
    "                \n",
    "                # resolve cache_transaction is blank\n",
    "                if len(cache_transaction.index) == 0  :\n",
    "                    d = {'storeId_HO': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                        'storeName_HO': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                        'productId': pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                        'productName': pool_1_transfer_clone.iloc[0]['productName'],\n",
    "                        'Quantity': n}\n",
    "                    \n",
    "                    #concat data to pool goods to HO\n",
    "                    pool_3_move_to_HO = pd.concat([pool_3_move_to_HO, pd.DataFrame(data=d,index=[0])], ignore_index=False)\n",
    "                    \n",
    "                    #drop good in first index in transfer pool when cache_transaction is blank\n",
    "                    pool_1_transfer_clone.drop(index = pool_1_transfer_clone.iloc[0:1,:].index, inplace=True)\n",
    "                    \n",
    "                    #break loop when pool_1_transfer is over\n",
    "                    if len(pool_1_transfer_clone.index) == 0: break\n",
    "\n",
    "                    #update cache_transaction with new first index items of pool_1_transfer_clone\n",
    "                    cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "                # The amount of goods lacked pool_2 \n",
    "                m   =   cache_transaction.iloc[0]['Balance_num']\n",
    "\n",
    "                ## Case : n >= m; exceed >= lack\n",
    "                if  n    >=   m :\n",
    "\n",
    "                    transfering =    n  -   m\n",
    "                    \n",
    "                # This dataframe is storing the transaction\n",
    "                    # create log's dataframe\n",
    "                    c = {'storeId_transfer': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                            'storeName_transfer': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                            'storeId_receive':    cache_transaction.iloc[0]['storeId'],\n",
    "                            'storeName_receive':  cache_transaction.iloc[0]['storeName'],\n",
    "                            'productId':          pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                            'productName':        pool_1_transfer_clone.iloc[0]['productName'],'Quantity': m}\n",
    "                    \n",
    "                    # concat transaction with log's dataframe\n",
    "                    transaction =    pd.concat([transaction,pd.DataFrame(data = c, index = [0])], ignore_index=False)\n",
    "\n",
    "                    # Update values in 2 pools\n",
    "                    # Update pool_1 - subtract (n - m = transfering)\n",
    "                    pool_1_transfer_clone.loc[pool_1_transfer_clone.index[0], ['Balance_num']] = transfering\n",
    "                    \n",
    "                    # Update pool_2 drop index in pool2\n",
    "                    pool_2_get_clone.drop(index = cache_transaction.iloc[0:1,:].index, inplace=True)\n",
    "\n",
    "                    #   ReArrange Pool to identify first index\n",
    "                    pool_1_transfer_clone = sort_by_balance(pool_1_transfer_clone)\n",
    "                    pool_2_get_clone = sort_by_balance(pool_2_get_clone)\n",
    "\n",
    "                    #   Update cache_transaction \n",
    "                    # When pool_2_get_clone is blank - don't need to receive goods then break loop\n",
    "                    if len(pool_2_get_clone.index) == 0:\n",
    "                        break\n",
    "                        \n",
    "                    # update cache\n",
    "                    cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "                    continue\n",
    "                    \n",
    "                # Case 2 lack > exceed (m > n, n != 0) \n",
    "                if m > n and (n != 0 or n != None)  :\n",
    "    \n",
    "                    transfering =    m  - n \n",
    "\n",
    "                    # This dataframe is storing the transaction\n",
    "\n",
    "                    e = {'storeId_transfer': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                            'storeName_transfer': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                            'storeId_receive':    cache_transaction.iloc[0]['storeId'],\n",
    "                            'storeName_receive':  cache_transaction.iloc[0]['storeName'],\n",
    "                            'productId':          pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                            'productName':        pool_1_transfer_clone.iloc[0]['productName'], 'Quantity': n}\n",
    "                    \n",
    "                    # Add logs transaction\n",
    "                    transaction =    pd.concat([transaction,pd.DataFrame(data = e, index=[0])], ignore_index=False)\n",
    "                    \n",
    "                    #   Update transfer number and delete row in pool_1\n",
    "                    pool_2_get_clone.loc[cache_transaction.index[0], ['Balance_num']] = transfering\n",
    "                    \n",
    "                    # Update stockQuantity in  pool_2_get_clone\n",
    "                    pool_2_get_clone.loc[cache_transaction.index[0], ['StockQuantity']] = transfering\n",
    "                    \n",
    "                    # drop numbers goods transfer in pool_1\n",
    "                    pool_1_transfer_clone.drop(index=pool_1_transfer_clone.iloc[0:1,:].index ,inplace=True)\n",
    "                    \n",
    "                    #   Refresh pool\n",
    "                    pool_1_transfer_clone = sort_by_balance(pool_1_transfer_clone)\n",
    "                    pool_2_get_clone = sort_by_balance(pool_2_get_clone)\n",
    "\n",
    "                    #   Breake when pool_1 is blank\n",
    "                    if len(pool_1_transfer_clone.index) == 0 :\n",
    "                        break\n",
    "                        \n",
    "                    #   Update cache transaction    \n",
    "                    cache_transaction=pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "                    continue\n",
    "                    \n",
    "                # Case 3 lack > exceed (m > n) (1 - 0 = 1, case when n = 0 or n = None)\n",
    "                if m > n and (n == 0 or n == None)  :\n",
    "    \n",
    "                    transfering = 0\n",
    "\n",
    "                    # This dataframe is storing the transaction\n",
    "\n",
    "                    e = {'storeId_transfer': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                            'storeName_transfer': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                            'storeId_receive':    cache_transaction.iloc[0]['storeId'],\n",
    "                            'storeName_receive':  cache_transaction.iloc[0]['storeName'],\n",
    "                            'productId':          pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                            'productName':        pool_1_transfer_clone.iloc[0]['productName'], 'Quantity': n}\n",
    "                    \n",
    "                    # Add logs transaction\n",
    "                    transaction =    pd.concat([transaction,pd.DataFrame(data = e, index=[0])], ignore_index=False)\n",
    "                    \n",
    "                    #   Update transfer number and delete row in pool_1\n",
    "                    pool_2_get_clone.loc[cache_transaction.index[0], ['Balance_num']] = m\n",
    "                    \n",
    "                    # Update stockQuantity in  pool_2_get_clone\n",
    "                    #pool_2_get_clone.loc[cache_transaction.index[0], ['StockQuantity']] = transfering\n",
    "                    \n",
    "                    # drop numbers goods transfer in pool_1\n",
    "                    pool_1_transfer_clone.drop(index=pool_1_transfer_clone.iloc[0:1,:].index ,inplace=True)\n",
    "                    \n",
    "                    #   Refresh pool\n",
    "                    pool_1_transfer_clone = sort_by_balance(pool_1_transfer_clone)\n",
    "                    pool_2_get_clone = sort_by_balance(pool_2_get_clone)\n",
    "\n",
    "                    #   Breake when pool_1 is blank\n",
    "                    if len(pool_1_transfer_clone.index) == 0 :\n",
    "                        break\n",
    "                        \n",
    "                    #   Update cache transaction    \n",
    "                    cache_transaction=pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "                    continue\n",
    "                    \n",
    "\n",
    "            # filter transactions > 0\n",
    "            transaction = transaction[transaction['Quantity']>0]\n",
    "            \n",
    "            # filter goods to HO with quanity > 0\n",
    "            pool_3_move_to_HO = pool_3_move_to_HO[pool_3_move_to_HO['Quantity']>0]\n",
    "            \n",
    "            # define excel out_path - file location and excel writer with engine\n",
    "            out_path = f\"{path}{data.iloc[0]['Area']}.xlsx\" #with areas\n",
    "            writer = pd.ExcelWriter(out_path , engine = 'xlsxwriter')\n",
    "            \n",
    "            # export transaction with areas\n",
    "            transaction.to_excel(writer, sheet_name=f\"transfer_{data.iloc[0]['Area']}\", encoding='utf-8-sig', index=False)\n",
    "            \n",
    "            # export list hàng thiếu hàng\n",
    "            drop_sub_columns_pool2(pool_2_get_clone).to_excel(writer, sheet_name=f\"Statement_{data.iloc[0]['Area']}_thiếuhàng\", encoding='utf-8-sig', index=False)\n",
    "            \n",
    "            # export list move to HO - Dư hàng\n",
    "            pool_3_move_to_HO.to_excel(writer, sheet_name = f\"Statement_{data.iloc[0]['Area']}_thừahàng\", encoding='utf-8-sig', index=False)\n",
    "            \n",
    "            pool1_tong_hop = pd.concat([pool1_tong_hop, pool_3_move_to_HO], ignore_index=True)\n",
    "            \n",
    "            pool2_tong_hop = pd.concat([pool2_tong_hop, drop_sub_columns_pool2(pool_2_get_clone)], ignore_index=True)\n",
    "            \n",
    "            writer.save()\n",
    "            \n",
    "        else: # Areas <> HCM, HN\n",
    "            # Append excess goods\n",
    "            list_pool_1.append( drop_sub_columns_pool1( pool_1.rename(columns={'Balance_num':'Quantity', 'storeId':'storeId_HO', 'storeName':'storeName_HO'}))) #Thừa hàng\n",
    "            \n",
    "            # Append lacked goods\n",
    "            list_pool_2.append( drop_sub_columns_pool2(pool_2))\n",
    "            \n",
    "            # Listing sheets of pool by Areas\n",
    "            list_sheet_name_pool_1.append(f\"{data.iloc[0]['Area']}_HO\") #Name for sheet_name in pool_1 # excess goods\n",
    "            list_sheet_name_pool_2.append(f\"HO_{data.iloc[0]['Area']}\") #Name for sheet_name in pool_2 # lacked goods\n",
    "\n",
    "        '''cmt'''\n",
    "\n",
    "    '''cmt'''\n",
    "    # define excel writer of excess goods by areas\n",
    "    writer_pool_1 = pd.ExcelWriter( f\"{path}danh sách store tỉnh thừa hàng.xlsx\" , engine='xlsxwriter')\n",
    "    # define excel writer of lacked goods by areas\n",
    "    writer_pool_2 = pd.ExcelWriter( f\"{path}danh sách store tỉnh thiếu hàng.xlsx\" , engine='xlsxwriter')\n",
    "    \n",
    "    # for loop to create a pool_tong_hop of excess, lacked goods by areas\n",
    "    for pool1, name_pool1, pool2, name_pool2 in zip(list_pool_1, list_sheet_name_pool_1, list_pool_2, list_sheet_name_pool_2):\n",
    "        \n",
    "        pool1.to_excel( writer_pool_1, sheet_name = name_pool1, encoding = 'utf-8-sig', index = False )\n",
    "\n",
    "        pool2.to_excel( writer_pool_2, sheet_name = name_pool2, encoding = 'utf-8-sig', index = False )\n",
    "        \n",
    "        pool1 = pool1.drop(['Area'], axis = 1)\n",
    "        \n",
    "        pool1_tong_hop = pd.concat([pool1_tong_hop, pool1], ignore_index = True)\n",
    "        \n",
    "        pool2_tong_hop = pd.concat([pool2_tong_hop, pool2], ignore_index = True)\n",
    "    \n",
    "    # saving changes\n",
    "    writer_pool_1.save()\n",
    "    writer_pool_2.save()\n",
    "    '''cmt'''\n",
    "    \n",
    "    # write pool_tong_hop to excel files\n",
    "    pool1_tong_hop.to_excel(f'{path}danh sách tất cả store thừa hàng.xlsx', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    pool2_tong_hop.to_excel(f'{path}danh sách tất cả store thiếu hàng.xlsx', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    pool1_tong_hop = pool1_tong_hop.rename(columns={'storeId_HO':'storeId', 'storeName_HO':'storeName', 'Quantity':'StockQuantity'})\n",
    "\n",
    "    '''cmt'''\n",
    "    \n",
    "    ### LOOP 2\n",
    "    # concat to update stocks in HO inventory from pool_excess_goods\n",
    "    df_stock_HO = pd.concat([df_1,pool1_tong_hop], ignore_index=True)\n",
    "    \n",
    "    # transform HO inventory dataframe\n",
    "    df_stock_HO = df_stock_HO.groupby(by=['productId', 'productName'])['StockQuantity'].sum()\n",
    "    df_stock_HO = df_stock_HO.reset_index()\n",
    "    df_stock_HO['storeId'] = '88003'\n",
    "    df_stock_HO['storeName'] = 'KHO_DP2'\n",
    "    df_stock_HO['Area'] = 'KHO_DP2'\n",
    "    df_stock_HO['SO1'] = 0\n",
    "    df_stock_HO['SO2'] = 0\n",
    "    df_stock_HO['SO3'] = 0\n",
    "    df_stock_HO['SO4'] = 0\n",
    "    df_stock_HO['AvgSO'] = 0\n",
    "    df_stock_HO = df_stock_HO.reindex(columns=['Area', 'storeId', 'storeName', 'productId', 'productName', 'SO1', 'SO2', 'SO3', 'SO4', 'AvgSO', 'StockQuantity'])\n",
    "    \n",
    "    # writes HO inventory after reviews goods from excess stores\n",
    "    #df_stock_HO.to_excel(f'{path}KHO_HO_sau_khi_nhận_hàng.xlsx', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # create dataframe to re-distribute goods to areas - loop 2\n",
    "    df_stock_HO = pd.concat([df_stock_HO, pool2_tong_hop], ignore_index=True)\n",
    "    \n",
    "    # fill np.nan and replace its with 0\n",
    "    df_stock_HO = df_stock_HO.fillna(np.nan).replace([np.nan], 0)\n",
    "    \n",
    "    # clip() to resolve negative numbers\n",
    "    df_stock_HO['AvgSO'] = df_stock_HO['AvgSO'].clip(lower=0)\n",
    "\n",
    "    # compute SellPower for new dataframe\n",
    "    df_stock_HO['SellPower'] = round(df_stock_HO['AvgSO'].div(7),3)\n",
    "    \n",
    "    # next, compute DOS \n",
    "    df_stock_HO['DOS'] = round(df_stock_HO['StockQuantity'] / df_stock_HO['SellPower'],0)\n",
    "\n",
    "    # sort values by DOS and identify goods statement, assign Balance_num for goods in HO inventory = 0\n",
    "    df_stock_HO = df_stock_HO.sort_values( by=['DOS'], ascending = False)\n",
    "    df_stock_HO['Statement'] = df_stock_HO['DOS'].apply(lambda x: DOS_Classify(x))\n",
    "    df_stock_HO['Balance_num'] = 0\n",
    "    \n",
    "    # for loop to compute realistic Balance_num\n",
    "    for i,row in df_stock_HO.iterrows():\n",
    "        val = row['Statement']\n",
    "\n",
    "        if val == \"Thừa hàng\":\n",
    "            df_stock_HO.at[i,'Balance_num']= math.ceil(df_stock_HO['StockQuantity'][i] - df_stock_HO['SellPower'][i] * max_day) \n",
    "            \n",
    "        if val == \"Thiếu hàng\":\n",
    "            df_stock_HO.at[i,'Balance_num'] = round(-df_stock_HO['StockQuantity'][i] + df_stock_HO['SellPower'][i] * min_day,0)\n",
    "            \n",
    "        if val == \"Đủ hàng\": df_stock_HO.at[i,'Balance_num'] = 0\n",
    "\n",
    "    # export df_stock_HO file to xlsx\n",
    "    df_stock_HO.to_excel(f'{path}stocks_HO_afer.xlsx', encoding = 'utf-8-sig')\n",
    "    \n",
    "    # Initialize pool_1 excess goods\n",
    "    pool_1 = df_stock_HO.loc[df_stock_HO['Statement'] == 'Thừa hàng']\n",
    "    pool_1 = sort_by_balance(pool_1)\n",
    "\n",
    "    ## Initialize pool_2 lacked goods\n",
    "    pool_2 = df_stock_HO.loc[df_stock_HO['Statement'] == 'Thiếu hàng'] \n",
    "    pool_2 = sort_by_balance(pool_2)\n",
    "\n",
    "    # identify new pool_1_transfer_clone ; pool_2_get_clone\n",
    "    pool_1_transfer_clone = pool_1\n",
    "    pool_2_get_clone = pool_2\n",
    "\n",
    "    # Identify\n",
    "    # First Initialize cache_transaction\n",
    "    cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "    \n",
    "    # create Transaction dataframe\n",
    "    ## Rule: Compare the productId and Balance number\n",
    "    transaction = pd.DataFrame(columns=['storeId_transfer','storeName_transfer', 'storeId_receive','storeName_receive', 'productId','productName', 'Quantity'])\n",
    "    \n",
    "    # create pool_3_move_to_HO ???\n",
    "    pool_3_move_to_HO = pd.DataFrame(columns=['storeId_HO', 'storeName_HO', 'productId','productName', 'Quantity'])\n",
    "    \n",
    "    while True:\n",
    "        # The amount of goods exceeded pool_1\n",
    "        n   =   pool_1_transfer_clone.iloc[0]['Balance_num']\n",
    "        \n",
    "        # resolve case when ca_transaction is blank\n",
    "        if len(cache_transaction.index) == 0  :\n",
    "            d = {'storeId_HO':  pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                'storeName_HO': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                'productId':          pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                'productName':        pool_1_transfer_clone.iloc[0]['productName'],\n",
    "                'Quantity':           n}\n",
    "            \n",
    "            # update pool_3_stay_HO\n",
    "            pool_3_move_to_HO = pd.concat([pool_3_move_to_HO, pd.DataFrame(data = d,index=[0])], ignore_index = False)\n",
    "            \n",
    "            # update pool_1 to select another items\n",
    "            pool_1_transfer_clone.drop(index = pool_1_transfer_clone.iloc[0:1,:].index, inplace = True)\n",
    "            \n",
    "            # condition to break loop\n",
    "            if len(pool_1_transfer_clone.index) == 0:\n",
    "                break\n",
    "                \n",
    "            # upadte cache_transaction\n",
    "            cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        # The amount of goods lacked pool_2 \n",
    "        m   =   cache_transaction.iloc[0]['Balance_num']\n",
    "\n",
    "        ## Case : if the exceed > lack\n",
    "        if  n    >=   m :\n",
    "\n",
    "            transfering = n - m\n",
    "        # This dataframe is storing the transaction\n",
    "            c = {'storeId_transfer': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                'storeName_transfer': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                'storeId_receive': cache_transaction.iloc[0]['storeId'],\n",
    "                'storeName_receive': cache_transaction.iloc[0]['storeName'],\n",
    "                'productId': pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                'productName': pool_1_transfer_clone.iloc[0]['productName'], 'Quantity': m}\n",
    "            \n",
    "            # create transaction dataframe\n",
    "            transaction = pd.concat([transaction,pd.DataFrame(data = c, index=[0])], ignore_index = False)\n",
    "\n",
    "            #   Migrate the value    \n",
    "            pool_1_transfer_clone.loc[pool_1_transfer_clone.index[0], ['Balance_num']] = transfering \n",
    "            \n",
    "            pool_2_get_clone.drop(index=cache_transaction.iloc[0:1,:].index, inplace=True)\n",
    "\n",
    "            #   Refresh\n",
    "            pool_1_transfer_clone = sort_by_balance(pool_1_transfer_clone)\n",
    "            pool_2_get_clone = sort_by_balance(pool_2_get_clone)\n",
    "\n",
    "            #   Update cache_transaction \n",
    "            if len(pool_2_get_clone.index)==0:\n",
    "                break\n",
    "            cache_transaction=pool_2_get_clone.loc[pool_2_get_clone['productId'] ==\n",
    "                                                pool_1_transfer_clone.iloc[0]['productId']]\n",
    "            continue\n",
    "            \n",
    "        #Case 2 lack > exceed\n",
    "        if m > n  :\n",
    "\n",
    "            transfering = m - n \n",
    "\n",
    "            # This dataframe is storing the transaction\n",
    "\n",
    "            e = {'storeId_transfer': pool_1_transfer_clone.iloc[0]['storeId'],\n",
    "                    'storeName_transfer': pool_1_transfer_clone.iloc[0]['storeName'], \n",
    "                    'storeId_receive': cache_transaction.iloc[0]['storeId'],\n",
    "                    'storeName_receive': cache_transaction.iloc[0]['storeName'],\n",
    "                    'productId': pool_1_transfer_clone.iloc[0]['productId'],\n",
    "                    'productName': pool_1_transfer_clone.iloc[0]['productName'], 'Quantity': n}\n",
    "\n",
    "            transaction = pd.concat([transaction,pd.DataFrame(data = e,index=[0])], ignore_index=False)\n",
    "            \n",
    "            #   Migrate values and delete perious row\n",
    "            pool_2_get_clone.loc[cache_transaction.index[0], ['Balance_num']] = transfering\n",
    "        \n",
    "            pool_1_transfer_clone.drop(index = pool_1_transfer_clone.iloc[0:1,:].index ,inplace=True)\n",
    "            \n",
    "            #   Refresh \n",
    "            pool_1_transfer_clone = sort_by_balance(pool_1_transfer_clone)\n",
    "            pool_2_get_clone = sort_by_balance(pool_2_get_clone)\n",
    "\n",
    "            #   Break loop when pool_1_transfer is blank\n",
    "            if len(pool_1_transfer_clone.index) == 0 :\n",
    "                break\n",
    "            \n",
    "            # update cache_transaction\n",
    "            cache_transaction = pool_2_get_clone.loc[pool_2_get_clone['productId'] == pool_1_transfer_clone.iloc[0]['productId']]\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    # filter transactions > 0\n",
    "    transaction = transaction[transaction['Quantity'] > 0]\n",
    "    \n",
    "    # filter quantity to HO > 0\n",
    "    pool_3_move_to_HO = pool_3_move_to_HO[pool_3_move_to_HO['Quantity'] > 0]\n",
    "    \n",
    "    out_path = f\"{path}KHO_HO_FINAL.xlsx\"\n",
    "    \n",
    "    # create writer\n",
    "    writer = pd.ExcelWriter(out_path ,engine = 'xlsxwriter')\n",
    "    \n",
    "    # save transtactions loop2 as excel sheet\n",
    "    transaction.to_excel(writer, sheet_name = f\"transaction_KHO_HO_FINAL\", encoding = 'utf-8-sig', index = False)\n",
    "    \n",
    "    # list of lacked items after loop 2\n",
    "    pool_2_get_clone = pool_2_get_clone[pool_2_get_clone[\"StockQuantity\"] > 0]\n",
    "    drop_sub_columns_pool2(pool_2_get_clone).to_excel(writer, sheet_name = f\"Statement_KHO_FINAL_thiếuhàng\", encoding = 'utf-8-sig', index = False)\n",
    "    \n",
    "    \n",
    "    pool_3_move_to_HO.to_excel(writer, sheet_name=f\"KHO_FINAL_thừahàng\", encoding = 'utf-8-sig', index = False)\n",
    "    \n",
    "    pool1_tong_hop=pd.concat([pool1_tong_hop, pool_3_move_to_HO], ignore_index=True)\n",
    "    \n",
    "    pool2_tong_hop=pd.concat([pool2_tong_hop, drop_sub_columns_pool2(pool_2_get_clone)], ignore_index=True)\n",
    "    writer.save()\n",
    "# ''''cmt'''\n",
    "\n",
    "    return True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc17a53a-b44f-46b2-8ce0-247d5f5c9e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allotment(df_1, df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13ecf3b-3362-48c7-b054-2274029b51a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_df\n",
    "raw_df = pd.read_excel(f'{path}Stocks.xlsx')\n",
    "raw_df = raw_df.fillna(0)\n",
    "raw_df['spId'] = raw_df.apply(lambda row: str(row['storeId']) + str(row['productId']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71dab064-7556-422d-90ce-7e59c37af673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfer HCM\n",
    "trans_1_hcm = pd.read_excel(f'{path}HồChíMinh.xlsx', sheet_name = 'transfer_HồChíMinh')\n",
    "trans_1_hcm['receive_id'] = trans_1_hcm.apply(lambda row: str(row['storeId_receive']) + str(row['productId']), axis = 1)\n",
    "trans_1_hcm['transfer_id'] = trans_1_hcm.apply(lambda row: str(row['storeId_transfer']) + str(row['productId']), axis = 1)\n",
    "\n",
    "receive_1_hcm = trans_1_hcm.groupby(by = 'receive_id', axis = 0, as_index = False).sum()\n",
    "\n",
    "transfer_1_hcm = trans_1_hcm.groupby(by = 'transfer_id', axis = 0, as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68702013-df54-4276-9c71-5ad5e0b65096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfer HN\n",
    "trans_1_hn = pd.read_excel(f'{path}HàNội.xlsx', sheet_name = 'transfer_HàNội')\n",
    "trans_1_hn['receive_id'] = trans_1_hn.apply(lambda row: str(row['storeId_receive']) + str(row['productId']), axis = 1)\n",
    "trans_1_hn['transfer_id'] = trans_1_hn.apply(lambda row: str(row['storeId_transfer']) + str(row['productId']), axis = 1)\n",
    "receive_1_hn = trans_1_hn.groupby(by = 'receive_id', axis = 0, as_index = False).sum()\n",
    "transfe_1_hn = trans_1_hn.groupby(by = 'transfer_id', axis = 0, as_index = False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78015024-669d-4334-a44e-4220fe8e04e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# move to HO - loop 1\n",
    "move_1_HO = pd.read_excel(f'{path}danh sách tất cả store thừa hàng.xlsx')\n",
    "move_1_HO['move_1_HO_id'] = move_1_HO.apply(lambda row: str(row['storeId_HO']) + str(row['productId']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e174ca-c34c-4c2d-9c7b-d749efd14fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# receive from HO - loop 2\n",
    "HO_to_store = pd.read_excel(f'{path}KHO_HO_FINAL.xlsx', sheet_name = 'transaction_KHO_HO_FINAL')\n",
    "HO_to_store['trans_2_id'] = HO_to_store.apply(lambda row: str(row['storeId_receive']) + str(row['productId']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa51b25-1596-4369-bac6-3cfc1db1cab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(receive_1_hcm.loc[:,['receive_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'receive_id')\n",
    "raw_df = raw_df.drop('receive_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'hcm_1_rec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7c7ad7-0116-4aae-aef2-f13dc1194406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(transfer_1_hcm.loc[:,['transfer_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'transfer_id')\n",
    "raw_df = raw_df.drop('transfer_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'hcm_1_trans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db23ab2-4b4b-4895-980a-f48edbcf86b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(receive_1_hn.loc[:,['receive_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'receive_id')\n",
    "raw_df = raw_df.drop('receive_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'hn_1_rec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0234acc8-d339-4310-950f-51c75c859df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(transfe_1_hn.loc[:,['transfer_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'transfer_id')\n",
    "raw_df = raw_df.drop('transfer_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'hn_1_trans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "007a8873-4791-4b74-aa6f-e96c785db08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(move_1_HO.loc[:,['move_1_HO_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'move_1_HO_id')\n",
    "raw_df = raw_df.drop('move_1_HO_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'move_1_HO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b4f1c9-9559-40a5-a0f7-c1bdb77f2224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df = raw_df.merge(HO_to_store.loc[:,['trans_2_id','Quantity']], how = 'left', left_on = 'spId', right_on = 'trans_2_id')\n",
    "raw_df = raw_df.drop('trans_2_id', axis = 1)\n",
    "raw_df = raw_df.rename(columns = {'Quantity': 'trans_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6648e4-5050-43ba-b31d-718e6a8785f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>storeId</th>\n",
       "      <th>storeName</th>\n",
       "      <th>brandName</th>\n",
       "      <th>Cat2022</th>\n",
       "      <th>productId</th>\n",
       "      <th>productName</th>\n",
       "      <th>StockQuantity</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SO2</th>\n",
       "      <th>...</th>\n",
       "      <th>SO4</th>\n",
       "      <th>AvgSO</th>\n",
       "      <th>spId</th>\n",
       "      <th>hcm_1_rec</th>\n",
       "      <th>hcm_1_trans</th>\n",
       "      <th>hn_1_rec</th>\n",
       "      <th>hn_1_trans</th>\n",
       "      <th>move_1_HO</th>\n",
       "      <th>trans_2</th>\n",
       "      <th>final_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>101856</td>\n",
       "      <td>DDV ĐN 60 Hàm Nghi</td>\n",
       "      <td>Apple</td>\n",
       "      <td>IPAD MỚI</td>\n",
       "      <td>50000198</td>\n",
       "      <td>APPLE IPAD 2021 10.2\" WIFI 64GB (CTY) - Bạc MK...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10185650000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>101856</td>\n",
       "      <td>DDV ĐN 60 Hàm Nghi</td>\n",
       "      <td>Apple</td>\n",
       "      <td>IPAD MỚI</td>\n",
       "      <td>50000199</td>\n",
       "      <td>APPLE IPAD 2021 10.2\" WIFI 64GB (CTY) - Xám MK...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>10185650000199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>101856</td>\n",
       "      <td>DDV ĐN 60 Hàm Nghi</td>\n",
       "      <td>Apple</td>\n",
       "      <td>IPAD MỚI</td>\n",
       "      <td>50011648</td>\n",
       "      <td>APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Xanh M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10185650011648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>101856</td>\n",
       "      <td>DDV ĐN 60 Hàm Nghi</td>\n",
       "      <td>Apple</td>\n",
       "      <td>IPAD MỚI</td>\n",
       "      <td>50011649</td>\n",
       "      <td>APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Hồng M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10185650011649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Đà Nẵng</td>\n",
       "      <td>101856</td>\n",
       "      <td>DDV ĐN 60 Hàm Nghi</td>\n",
       "      <td>Apple</td>\n",
       "      <td>IPAD MỚI</td>\n",
       "      <td>50011650</td>\n",
       "      <td>APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Vàng M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10185650011650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>Miền Tây</td>\n",
       "      <td>101862</td>\n",
       "      <td>DDV MT 160 30TH4</td>\n",
       "      <td>XiaoMi</td>\n",
       "      <td>XIAOMI, NOKIA</td>\n",
       "      <td>50014617</td>\n",
       "      <td>XIAOMI REDMI 12C 4GB/64GB(CTY) - Xanh lá cây -...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10186250014617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>Miền Tây</td>\n",
       "      <td>101862</td>\n",
       "      <td>DDV MT 160 30TH4</td>\n",
       "      <td>XiaoMi</td>\n",
       "      <td>XIAOMI, NOKIA</td>\n",
       "      <td>50014618</td>\n",
       "      <td>XIAOMI REDMI 12C 4GB/64GB(CTY) - Xám - New</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10186250014618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>Miền Tây</td>\n",
       "      <td>101862</td>\n",
       "      <td>DDV MT 160 30TH4</td>\n",
       "      <td>XiaoMi</td>\n",
       "      <td>XIAOMI, NOKIA</td>\n",
       "      <td>50015167</td>\n",
       "      <td>XIAOMI REDMI NOTE 12 4GB/128GB(CTY) - Xanh dươ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10186250015167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>Miền Tây</td>\n",
       "      <td>101862</td>\n",
       "      <td>DDV MT 160 30TH4</td>\n",
       "      <td>XiaoMi</td>\n",
       "      <td>XIAOMI, NOKIA</td>\n",
       "      <td>50015168</td>\n",
       "      <td>XIAOMI REDMI NOTE 12 4GB/128GB(CTY) - Xám - New</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10186250015168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>Miền Tây</td>\n",
       "      <td>101862</td>\n",
       "      <td>DDV MT 160 30TH4</td>\n",
       "      <td>XiaoMi</td>\n",
       "      <td>XIAOMI, NOKIA</td>\n",
       "      <td>50015172</td>\n",
       "      <td>XIAOMI REDMI NOTE 12 PRO 5G 8GB/256GB(CTY) - Đ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10186250015172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5279 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Area  storeId           storeName brandName        Cat2022  \\\n",
       "0      Đà Nẵng   101856  DDV ĐN 60 Hàm Nghi     Apple      IPAD MỚI   \n",
       "1      Đà Nẵng   101856  DDV ĐN 60 Hàm Nghi     Apple      IPAD MỚI   \n",
       "2      Đà Nẵng   101856  DDV ĐN 60 Hàm Nghi     Apple      IPAD MỚI   \n",
       "3      Đà Nẵng   101856  DDV ĐN 60 Hàm Nghi     Apple      IPAD MỚI   \n",
       "4      Đà Nẵng   101856  DDV ĐN 60 Hàm Nghi     Apple      IPAD MỚI   \n",
       "...        ...      ...                 ...       ...            ...   \n",
       "5274  Miền Tây   101862    DDV MT 160 30TH4    XiaoMi  XIAOMI, NOKIA   \n",
       "5275  Miền Tây   101862    DDV MT 160 30TH4    XiaoMi  XIAOMI, NOKIA   \n",
       "5276  Miền Tây   101862    DDV MT 160 30TH4    XiaoMi  XIAOMI, NOKIA   \n",
       "5277  Miền Tây   101862    DDV MT 160 30TH4    XiaoMi  XIAOMI, NOKIA   \n",
       "5278  Miền Tây   101862    DDV MT 160 30TH4    XiaoMi  XIAOMI, NOKIA   \n",
       "\n",
       "      productId                                        productName  \\\n",
       "0      50000198  APPLE IPAD 2021 10.2\" WIFI 64GB (CTY) - Bạc MK...   \n",
       "1      50000199  APPLE IPAD 2021 10.2\" WIFI 64GB (CTY) - Xám MK...   \n",
       "2      50011648  APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Xanh M...   \n",
       "3      50011649  APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Hồng M...   \n",
       "4      50011650  APPLE IPAD 2022 10.9\" WIFI 64GB (CTY) - Vàng M...   \n",
       "...         ...                                                ...   \n",
       "5274   50014617  XIAOMI REDMI 12C 4GB/64GB(CTY) - Xanh lá cây -...   \n",
       "5275   50014618         XIAOMI REDMI 12C 4GB/64GB(CTY) - Xám - New   \n",
       "5276   50015167  XIAOMI REDMI NOTE 12 4GB/128GB(CTY) - Xanh dươ...   \n",
       "5277   50015168    XIAOMI REDMI NOTE 12 4GB/128GB(CTY) - Xám - New   \n",
       "5278   50015172  XIAOMI REDMI NOTE 12 PRO 5G 8GB/256GB(CTY) - Đ...   \n",
       "\n",
       "      StockQuantity  SO1  SO2  ...  SO4  AvgSO            spId hcm_1_rec  \\\n",
       "0               2.0  0.0  1.0  ...  2.0   1.00  10185650000198       0.0   \n",
       "1               0.0  3.0  2.0  ...  3.0   2.50  10185650000199       0.0   \n",
       "2               0.0  0.0  0.0  ...  0.0   0.50  10185650011648       0.0   \n",
       "3               0.0  0.0  0.0  ...  1.0   0.25  10185650011649       0.0   \n",
       "4               0.0  0.0  0.0  ...  0.0   0.25  10185650011650       0.0   \n",
       "...             ...  ...  ...  ...  ...    ...             ...       ...   \n",
       "5274            1.0  0.0  1.0  ...  0.0   0.25  10186250014617       0.0   \n",
       "5275            2.0  0.0  0.0  ...  0.0   0.25  10186250014618       0.0   \n",
       "5276            4.0  0.0  1.0  ...  0.0   0.25  10186250015167       0.0   \n",
       "5277            7.0  0.0  0.0  ...  0.0   0.00  10186250015168       0.0   \n",
       "5278            2.0  0.0  0.0  ...  0.0   0.00  10186250015172       0.0   \n",
       "\n",
       "      hcm_1_trans  hn_1_rec  hn_1_trans  move_1_HO  trans_2  final_quantity  \n",
       "0             0.0       0.0         0.0        0.0      0.0             2.0  \n",
       "1             0.0       0.0         0.0        0.0      0.0             0.0  \n",
       "2             0.0       0.0         0.0        0.0      0.0             0.0  \n",
       "3             0.0       0.0         0.0        0.0      0.0             0.0  \n",
       "4             0.0       0.0         0.0        0.0      0.0             0.0  \n",
       "...           ...       ...         ...        ...      ...             ...  \n",
       "5274          0.0       0.0         0.0        0.0      0.0             1.0  \n",
       "5275          0.0       0.0         0.0        1.0      0.0             1.0  \n",
       "5276          0.0       0.0         0.0        3.0      0.0             1.0  \n",
       "5277          0.0       0.0         0.0        7.0      0.0             0.0  \n",
       "5278          0.0       0.0         0.0        2.0      0.0             0.0  \n",
       "\n",
       "[5279 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = raw_df.fillna(0)\n",
    "raw_df['final_quantity'] = raw_df['StockQuantity'] + raw_df['hcm_1_rec'] - raw_df['hcm_1_trans'] + raw_df['hn_1_rec'] \\\n",
    "                            - raw_df['hn_1_trans'] - raw_df['move_1_HO'] + raw_df['trans_2']\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73497992-226d-48bb-96bb-12de86f4ea1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_df.to_excel(f'{path}finalStocks.xlsx', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8041e9-29e3-4126-8d26-e5ed0bd85075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
